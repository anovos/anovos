#input_dataset: ETL configurations of main dataset.
#input_dataset can be renamed but need to change the name in main script as well
#keys of input_dataset are function names (cannot be renamed) & values are function arguments (value can be null to skip except for read_dataset)
#delete_column/select_column: arguments can be in front or under as list_of_cols
#list_of_cols: list or string with multiple columns separated by | (refer doc string for further details)
input_dataset:
  read_dataset:
    file_path: "data/income_dataset/csv"
    file_type: csv
    file_configs:
      header: True
      delimiter: ","
      inferSchema: True
  delete_column: ['logfnl']
  select_column: null
  rename_column:
    list_of_cols: ['marital-status','education-num']
    list_of_newcols: ['marital_status','education_num']
  recast_column:
    list_of_cols: ['age','education_num']
    list_of_dtypes: ['float','float']

anovos_basic_report:
  basic_report: False
  report_args:
    id_col: ifa
    label_col: income
    event_label: '>50K'
    skip_corr_matrix: True
    output_path: report_stats

write_intermediate:
  file_path: "intermediate_data"
  file_type: csv
  file_configs:
    mode: overwrite
    header: True
    delimiter: ","
    inferSchema: True

write_main:
  file_path: "../anovos_repo/data/output/"
  file_type: parquet
  file_configs:
    mode: overwrite

write_stats:
  file_path: "stats"
  file_type: parquet
  file_configs:
    mode: overwrite
